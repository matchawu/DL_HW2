{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "from PIL import Image\n",
    "import torch\n",
    "import torchvision\n",
    "import torch.optim as optim\n",
    "from torchvision import transforms\n",
    "from torch.autograd import Variable\n",
    "from torchvision.datasets import ImageFolder\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision.utils import save_image\n",
    "from random import randint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "number of train data: 19395\nnumber of test data: 2156\n"
    }
   ],
   "source": [
    "epochs = 15\n",
    "batch_size = 64# num_workers = 2   # num_workers\n",
    "latent_code = 32   \n",
    "\n",
    "batch = len(trainSet) / batch_size\n",
    "image_size = int(64 * 64 * 3)\n",
    "mean = (0.5, 0.5, 0.5)\n",
    "std = (0.5, 0.5, 0.5)\n",
    "\n",
    "data_path = '../anime-faces/data/'\n",
    "transform = transforms.Compose(\n",
    "    [\n",
    "        transforms.Resize((64,64)), # resize images to same size\n",
    "        torchvision.transforms.ToTensor(), # image to tensor\n",
    "        transforms.Normalize(mean, std)\n",
    "    ]\n",
    ")\n",
    "\n",
    "# dataset\n",
    "dataset = torchvision.datasets.ImageFolder(\n",
    "    root=data_path,\n",
    "    transform=transform\n",
    ")\n",
    "\n",
    "# train test split\n",
    "num_data = len(dataset)\n",
    "ratio = .9\n",
    "# print(num_data)\n",
    "# print(int(num_data*0.8), num_data-int(num_data*0.8))\n",
    "trainSet, testSet = torch.utils.data.random_split(dataset, [int(num_data*ratio), num_data-int(num_data*ratio)])\n",
    "print(\"number of train data:\", len(trainSet))\n",
    "print(\"number of test data:\", len(testSet))\n",
    "\n",
    "# dataloader\n",
    "trainLoader = torch.utils.data.DataLoader(\n",
    "    trainSet,\n",
    "    batch_size=batch_size,\n",
    "    num_workers=0,\n",
    "    shuffle=True\n",
    ")\n",
    "testLoader = torch.utils.data.DataLoader(\n",
    "    testSet,\n",
    "    batch_size=batch_size,\n",
    "    num_workers=0,\n",
    "    shuffle=True\n",
    ")\n",
    "# print(train_loader.dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# '''\n",
    "# 公式如下: \n",
    "# new_height = new_width = (W — F + 1) / S （结果向上取整數，假設算出來結果是4.5，取5）\n",
    "# (原本 - filter + 1) / stride\n",
    "\n",
    "# 例子\n",
    "# filter 3x3, stride=1, 卷積後的大小: (10–3+1)/1=8\n",
    "# filter 3x3, stride=2, 卷積後的大小: (10–3+1)/2=4\n",
    "# '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CNN VAE\n",
    "class Flatten(nn.Module):\n",
    "    def forward(self, input):\n",
    "        return input.view(input.size(0), -1)\n",
    "class UnFlatten(nn.Module):\n",
    "    def forward(self, input, size=1024):\n",
    "        return input.view(input.size(0), size, 1, 1)\n",
    "\n",
    "class VAE(nn.Module):\n",
    "    def __init__(self, image_channels=3, h_dim=1024, z_dim=32):\n",
    "        super(VAE, self).__init__()\n",
    "\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Conv2d(image_channels, 32, kernel_size=4, stride=2),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(32, 64, kernel_size=4, stride=2),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(64, 128, kernel_size=4, stride=2),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(128, 256, kernel_size=4, stride=2),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU(),\n",
    "            Flatten()\n",
    "        )\n",
    "        self.fc1 = nn.Linear(h_dim, z_dim)\n",
    "        self.fc2 = nn.Linear(h_dim, z_dim)\n",
    "        self.fc3 = nn.Linear(z_dim, h_dim)\n",
    "\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "        self.decoder = nn.Sequential(\n",
    "            UnFlatten(),\n",
    "            nn.ConvTranspose2d(h_dim, 128, kernel_size=5, stride=2),\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(128, 64, kernel_size=5, stride=2),\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(64, 32, kernel_size=6, stride=2),\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(32, image_channels, kernel_size=6, stride=2),\n",
    "            nn.Sigmoid(),\n",
    "        )\n",
    "    def reparameterize(self, mu, logvar):\n",
    "        std = logvar.mul(0.5).exp_()\n",
    "        # return torch.normal(mu, std)\n",
    "        esp = torch.randn(*mu.size())\n",
    "        z = mu + std * esp\n",
    "        return z\n",
    "    \n",
    "    def bottleneck(self, h):\n",
    "        mu, logvar = self.fc1(h), self.fc2(h)\n",
    "        z = self.reparameterize(mu, logvar)\n",
    "        return z, mu, logvar\n",
    "\n",
    "    def encode(self, x):\n",
    "        h = self.encoder(x)\n",
    "        z, mu, logvar = self.bottleneck(h)\n",
    "        return z, mu, logvar\n",
    "\n",
    "    def decode(self, z):\n",
    "        z = self.fc3(z)\n",
    "        z = self.decoder(z)\n",
    "        return z\n",
    "\n",
    "    def forward(self, x):\n",
    "        z, mu, logvar = self.encode(x)\n",
    "        z = self.decode(z)\n",
    "        return z, mu, logvar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "0.5 0.5\n0.5 0.5\n0.5 0.5\n"
    }
   ],
   "source": [
    "def UnNormalization(tensor):\n",
    "    for t, m, s in zip(tensor, mean, std):\n",
    "        t.mul_(s).add_(m)\n",
    "        print(s,m)\n",
    "    return tensor\n",
    "sample = Variable(torch.randn(batch_size, 32))\n",
    "sample_recon = vae.decoder(vae.fc3(sample).view(batch_size, 1024, 1, 1))\n",
    "save_image(UnNormalization(sample_recon.data.view(batch_size, 3, 64, 64)), './result/un_epoch_' +str(epoch) + '.png')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "'''\n",
    "loss function\n",
    "'''\n",
    "def loss_fn(recon_x, x, mu, logvar):\n",
    "    BCE = F.binary_cross_entropy(recon_x, torch.sigmoid(x), size_average=False)\n",
    "    KLD = -0.5 * torch.mean(1 + logvar - mu.pow(2) - logvar.exp())\n",
    "    return BCE + KLD*100, BCE, KLD\n",
    "# '''\n",
    "# model summary\n",
    "# '''\n",
    "# from torchvision import models\n",
    "# from torchsummary import summary\n",
    "# summary(vae, (3, 64, 64))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare(x):\n",
    "    recon_x, _, _ = vae(x) #x/255.\n",
    "    return torch.cat([x, recon_x]) #x/255."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "tags": [
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": " Training Loss: 8077.337\nEpoch[30/100] Testing Loss: 8088.967\n-----------------------------------------------------\nEpoch[31/100] Loss: 8075.249 BCE: 8075.155 KL: 0.094\nEpoch[31/100] Loss: 8088.928 BCE: 8088.835 KL: 0.093\n0.5 0.5\n0.5 0.5\n0.5 0.5\nSave samples finished...\nEpoch[31/100] Training Loss: 8076.769\nEpoch[31/100] Testing Loss: 8091.027\n-----------------------------------------------------\nEpoch[32/100] Loss: 8085.312 BCE: 8085.221 KL: 0.091\nEpoch[32/100] Loss: 8069.220 BCE: 8069.128 KL: 0.092\n0.5 0.5\n0.5 0.5\n0.5 0.5\nSave samples finished...\nEpoch[32/100] Training Loss: 8076.462\nEpoch[32/100] Testing Loss: 8088.863\n-----------------------------------------------------\nEpoch[33/100] Loss: 8099.808 BCE: 8099.715 KL: 0.092\nEpoch[33/100] Loss: 8077.180 BCE: 8077.089 KL: 0.091\n0.5 0.5\n0.5 0.5\n0.5 0.5\nSave samples finished...\nEpoch[33/100] Training Loss: 8075.981\nEpoch[33/100] Testing Loss: 8088.281\n-----------------------------------------------------\nEpoch[34/100] Loss: 8064.811 BCE: 8064.721 KL: 0.090\nEpoch[34/100] Loss: 8074.153 BCE: 8074.061 KL: 0.092\n0.5 0.5\n0.5 0.5\n0.5 0.5\nSave samples finished...\nEpoch[34/100] Training Loss: 8075.809\nEpoch[34/100] Testing Loss: 8088.519\n-----------------------------------------------------\nEpoch[35/100] Loss: 8076.858 BCE: 8076.764 KL: 0.094\nEpoch[35/100] Loss: 8079.120 BCE: 8079.026 KL: 0.093\n0.5 0.5\n0.5 0.5\n0.5 0.5\nSave samples finished...\nEpoch[35/100] Training Loss: 8075.525\nEpoch[35/100] Testing Loss: 8090.612\n-----------------------------------------------------\nEpoch[36/100] Loss: 8076.744 BCE: 8076.650 KL: 0.093\nEpoch[36/100] Loss: 8071.243 BCE: 8071.151 KL: 0.092\n0.5 0.5\n0.5 0.5\n0.5 0.5\nSave samples finished...\nEpoch[36/100] Training Loss: 8075.371\nEpoch[36/100] Testing Loss: 8089.638\n-----------------------------------------------------\nEpoch[37/100] Loss: 8064.914 BCE: 8064.822 KL: 0.092\nEpoch[37/100] Loss: 8104.818 BCE: 8104.726 KL: 0.092\n0.5 0.5\n0.5 0.5\n0.5 0.5\nSave samples finished...\nEpoch[37/100] Training Loss: 8074.839\nEpoch[37/100] Testing Loss: 8089.347\n-----------------------------------------------------\nEpoch[38/100] Loss: 8066.010 BCE: 8065.917 KL: 0.092\nEpoch[38/100] Loss: 8058.084 BCE: 8057.994 KL: 0.090\n0.5 0.5\n0.5 0.5\n0.5 0.5\nSave samples finished...\nEpoch[38/100] Training Loss: 8074.696\nEpoch[38/100] Testing Loss: 8092.782\n-----------------------------------------------------\nEpoch[39/100] Loss: 8084.310 BCE: 8084.220 KL: 0.090\nEpoch[39/100] Loss: 8066.181 BCE: 8066.089 KL: 0.092\n0.5 0.5\n0.5 0.5\n0.5 0.5\nSave samples finished...\nEpoch[39/100] Training Loss: 8074.587\nEpoch[39/100] Testing Loss: 8088.097\n-----------------------------------------------------\nEpoch[40/100] Loss: 8070.014 BCE: 8069.921 KL: 0.093\nEpoch[40/100] Loss: 8050.524 BCE: 8050.435 KL: 0.089\n0.5 0.5\n0.5 0.5\n0.5 0.5\nSave samples finished...\nEpoch[40/100] Training Loss: 8074.138\nEpoch[40/100] Testing Loss: 8089.358\n-----------------------------------------------------\nEpoch[41/100] Loss: 8094.496 BCE: 8094.403 KL: 0.093\nEpoch[41/100] Loss: 8064.297 BCE: 8064.205 KL: 0.093\n0.5 0.5\n0.5 0.5\n0.5 0.5\nSave samples finished...\nEpoch[41/100] Training Loss: 8073.802\nEpoch[41/100] Testing Loss: 8095.065\n-----------------------------------------------------\nEpoch[42/100] Loss: 8054.786 BCE: 8054.697 KL: 0.089\nEpoch[42/100] Loss: 8081.268 BCE: 8081.176 KL: 0.092\n0.5 0.5\n0.5 0.5\n0.5 0.5\nSave samples finished...\nEpoch[42/100] Training Loss: 8073.853\nEpoch[42/100] Testing Loss: 8091.894\n-----------------------------------------------------\nEpoch[43/100] Loss: 8069.643 BCE: 8069.552 KL: 0.091\nEpoch[43/100] Loss: 8048.946 BCE: 8048.856 KL: 0.090\n0.5 0.5\n0.5 0.5\n0.5 0.5\nSave samples finished...\nEpoch[43/100] Training Loss: 8073.859\nEpoch[43/100] Testing Loss: 8088.606\n-----------------------------------------------------\nEpoch[44/100] Loss: 8080.478 BCE: 8080.389 KL: 0.089\nEpoch[44/100] Loss: 8106.867 BCE: 8106.776 KL: 0.091\n0.5 0.5\n0.5 0.5\n0.5 0.5\nSave samples finished...\nEpoch[44/100] Training Loss: 8073.208\nEpoch[44/100] Testing Loss: 8088.366\n-----------------------------------------------------\nEpoch[45/100] Loss: 8050.625 BCE: 8050.535 KL: 0.090\nEpoch[45/100] Loss: 8091.264 BCE: 8091.171 KL: 0.092\n0.5 0.5\n0.5 0.5\n0.5 0.5\nSave samples finished...\nEpoch[45/100] Training Loss: 8072.945\nEpoch[45/100] Testing Loss: 8087.949\n-----------------------------------------------------\nEpoch[46/100] Loss: 8100.608 BCE: 8100.514 KL: 0.094\nEpoch[46/100] Loss: 8076.535 BCE: 8076.443 KL: 0.092\n0.5 0.5\n0.5 0.5\n0.5 0.5\nSave samples finished...\nEpoch[46/100] Training Loss: 8072.656\nEpoch[46/100] Testing Loss: 8089.337\n-----------------------------------------------------\nEpoch[47/100] Loss: 8082.919 BCE: 8082.829 KL: 0.090\nEpoch[47/100] Loss: 8089.345 BCE: 8089.253 KL: 0.092\n0.5 0.5\n0.5 0.5\n0.5 0.5\nSave samples finished...\nEpoch[47/100] Training Loss: 8072.367\nEpoch[47/100] Testing Loss: 8088.451\n-----------------------------------------------------\nEpoch[48/100] Loss: 8075.951 BCE: 8075.860 KL: 0.091\nEpoch[48/100] Loss: 8082.768 BCE: 8082.676 KL: 0.092\n0.5 0.5\n0.5 0.5\n0.5 0.5\nSave samples finished...\nEpoch[48/100] Training Loss: 8072.621\nEpoch[48/100] Testing Loss: 8089.369\n-----------------------------------------------------\nEpoch[49/100] Loss: 8052.178 BCE: 8052.087 KL: 0.090\nEpoch[49/100] Loss: 8073.806 BCE: 8073.715 KL: 0.091\n0.5 0.5\n0.5 0.5\n0.5 0.5\nSave samples finished...\nEpoch[49/100] Training Loss: 8072.397\nEpoch[49/100] Testing Loss: 8088.394\n-----------------------------------------------------\nEpoch[50/100] Loss: 8074.290 BCE: 8074.200 KL: 0.090\nEpoch[50/100] Loss: 8039.169 BCE: 8039.081 KL: 0.088\n0.5 0.5\n0.5 0.5\n0.5 0.5\nSave samples finished...\nEpoch[50/100] Training Loss: 8072.041\nEpoch[50/100] Testing Loss: 8095.159\n-----------------------------------------------------\nEpoch[51/100] Loss: 8070.913 BCE: 8070.821 KL: 0.092\nEpoch[51/100] Loss: 8063.643 BCE: 8063.550 KL: 0.093\n0.5 0.5\n0.5 0.5\n0.5 0.5\nSave samples finished...\nEpoch[51/100] Training Loss: 8071.761\nEpoch[51/100] Testing Loss: 8088.943\n-----------------------------------------------------\nEpoch[52/100] Loss: 8059.038 BCE: 8058.947 KL: 0.091\nEpoch[52/100] Loss: 8083.485 BCE: 8083.395 KL: 0.090\n0.5 0.5\n0.5 0.5\n0.5 0.5\nSave samples finished...\nEpoch[52/100] Training Loss: 8071.736\nEpoch[52/100] Testing Loss: 8091.981\n-----------------------------------------------------\nEpoch[53/100] Loss: 8082.771 BCE: 8082.682 KL: 0.090\nEpoch[53/100] Loss: 8069.161 BCE: 8069.072 KL: 0.088\n0.5 0.5\n0.5 0.5\n0.5 0.5\nSave samples finished...\nEpoch[53/100] Training Loss: 8072.178\nEpoch[53/100] Testing Loss: 8090.998\n-----------------------------------------------------\nEpoch[54/100] Loss: 8069.062 BCE: 8068.971 KL: 0.090\nEpoch[54/100] Loss: 8066.487 BCE: 8066.397 KL: 0.089\n0.5 0.5\n0.5 0.5\n0.5 0.5\nSave samples finished...\nEpoch[54/100] Training Loss: 8071.410\nEpoch[54/100] Testing Loss: 8088.422\n-----------------------------------------------------\nEpoch[55/100] Loss: 8080.495 BCE: 8080.404 KL: 0.091\nEpoch[55/100] Loss: 8083.223 BCE: 8083.133 KL: 0.090\n0.5 0.5\n0.5 0.5\n0.5 0.5\nSave samples finished...\nEpoch[55/100] Training Loss: 8071.202\nEpoch[55/100] Testing Loss: 8088.857\n-----------------------------------------------------\nEpoch[56/100] Loss: 8050.273 BCE: 8050.184 KL: 0.090\nEpoch[56/100] Loss: 8080.811 BCE: 8080.723 KL: 0.089\n0.5 0.5\n0.5 0.5\n0.5 0.5\nSave samples finished...\nEpoch[56/100] Training Loss: 8070.887\nEpoch[56/100] Testing Loss: 8088.401\n-----------------------------------------------------\nEpoch[57/100] Loss: 8078.622 BCE: 8078.530 KL: 0.091\nEpoch[57/100] Loss: 8093.013 BCE: 8092.922 KL: 0.091\n0.5 0.5\n0.5 0.5\n0.5 0.5\nSave samples finished...\nEpoch[57/100] Training Loss: 8070.932\nEpoch[57/100] Testing Loss: 8089.043\n-----------------------------------------------------\nEpoch[58/100] Loss: 8095.711 BCE: 8095.621 KL: 0.090\nEpoch[58/100] Loss: 8068.829 BCE: 8068.737 KL: 0.091\n0.5 0.5\n0.5 0.5\n0.5 0.5\nSave samples finished...\nEpoch[58/100] Training Loss: 8070.782\nEpoch[58/100] Testing Loss: 8089.190\n-----------------------------------------------------\nEpoch[59/100] Loss: 8070.648 BCE: 8070.559 KL: 0.089\nEpoch[59/100] Loss: 8065.664 BCE: 8065.575 KL: 0.089\n0.5 0.5\n0.5 0.5\n0.5 0.5\nSave samples finished...\nEpoch[59/100] Training Loss: 8070.657\nEpoch[59/100] Testing Loss: 8090.424\n-----------------------------------------------------\nEpoch[60/100] Loss: 8065.886 BCE: 8065.797 KL: 0.089\nEpoch[60/100] Loss: 8072.767 BCE: 8072.677 KL: 0.090\n0.5 0.5\n0.5 0.5\n0.5 0.5\nSave samples finished...\nEpoch[60/100] Training Loss: 8070.582\nEpoch[60/100] Testing Loss: 8091.967\n-----------------------------------------------------\nEpoch[61/100] Loss: 8072.391 BCE: 8072.298 KL: 0.093\nEpoch[61/100] Loss: 8074.351 BCE: 8074.262 KL: 0.089\n0.5 0.5\n0.5 0.5\n0.5 0.5\nSave samples finished...\nEpoch[61/100] Training Loss: 8070.461\nEpoch[61/100] Testing Loss: 8089.292\n-----------------------------------------------------\nEpoch[62/100] Loss: 8058.874 BCE: 8058.785 KL: 0.089\nEpoch[62/100] Loss: 8077.711 BCE: 8077.622 KL: 0.089\n0.5 0.5\n0.5 0.5\n0.5 0.5\nSave samples finished...\nEpoch[62/100] Training Loss: 8070.259\nEpoch[62/100] Testing Loss: 8089.283\n-----------------------------------------------------\nEpoch[63/100] Loss: 8079.478 BCE: 8079.388 KL: 0.090\nEpoch[63/100] Loss: 8076.653 BCE: 8076.565 KL: 0.088\n0.5 0.5\n0.5 0.5\n0.5 0.5\nSave samples finished...\nEpoch[63/100] Training Loss: 8070.052\nEpoch[63/100] Testing Loss: 8088.930\n-----------------------------------------------------\nEpoch[64/100] Loss: 8075.765 BCE: 8075.676 KL: 0.089\nEpoch[64/100] Loss: 8049.266 BCE: 8049.178 KL: 0.088\n0.5 0.5\n0.5 0.5\n0.5 0.5\nSave samples finished...\nEpoch[64/100] Training Loss: 8069.987\nEpoch[64/100] Testing Loss: 8088.594\n-----------------------------------------------------\nEpoch[65/100] Loss: 8070.125 BCE: 8070.038 KL: 0.088\nEpoch[65/100] Loss: 8096.373 BCE: 8096.283 KL: 0.089\n0.5 0.5\n0.5 0.5\n0.5 0.5\nSave samples finished...\nEpoch[65/100] Training Loss: 8069.493\nEpoch[65/100] Testing Loss: 8088.364\n-----------------------------------------------------\nEpoch[66/100] Loss: 8077.584 BCE: 8077.495 KL: 0.090\nEpoch[66/100] Loss: 8102.468 BCE: 8102.377 KL: 0.091\n0.5 0.5\n0.5 0.5\n0.5 0.5\nSave samples finished...\nEpoch[66/100] Training Loss: 8069.386\nEpoch[66/100] Testing Loss: 8088.696\n-----------------------------------------------------\nEpoch[67/100] Loss: 8070.219 BCE: 8070.131 KL: 0.088\nEpoch[67/100] Loss: 8044.942 BCE: 8044.853 KL: 0.089\n0.5 0.5\n0.5 0.5\n0.5 0.5\nSave samples finished...\nEpoch[67/100] Training Loss: 8069.486\nEpoch[67/100] Testing Loss: 8090.324\n-----------------------------------------------------\nEpoch[68/100] Loss: 8096.950 BCE: 8096.861 KL: 0.089\nEpoch[68/100] Loss: 8095.596 BCE: 8095.506 KL: 0.090\n0.5 0.5\n0.5 0.5\n0.5 0.5\nSave samples finished...\nEpoch[68/100] Training Loss: 8069.678\nEpoch[68/100] Testing Loss: 8090.911\n-----------------------------------------------------\nEpoch[69/100] Loss: 8063.004 BCE: 8062.913 KL: 0.091\nEpoch[69/100] Loss: 8040.629 BCE: 8040.540 KL: 0.090\n0.5 0.5\n0.5 0.5\n0.5 0.5\nSave samples finished...\nEpoch[69/100] Training Loss: 8069.371\nEpoch[69/100] Testing Loss: 8089.124\n-----------------------------------------------------\nEpoch[70/100] Loss: 8066.823 BCE: 8066.732 KL: 0.091\nEpoch[70/100] Loss: 8073.191 BCE: 8073.101 KL: 0.091\n0.5 0.5\n0.5 0.5\n0.5 0.5\nSave samples finished...\nEpoch[70/100] Training Loss: 8069.568\nEpoch[70/100] Testing Loss: 8092.043\n-----------------------------------------------------\nEpoch[71/100] Loss: 8043.753 BCE: 8043.665 KL: 0.088\nEpoch[71/100] Loss: 8080.903 BCE: 8080.814 KL: 0.089\n0.5 0.5\n0.5 0.5\n0.5 0.5\nSave samples finished...\nEpoch[71/100] Training Loss: 8069.084\nEpoch[71/100] Testing Loss: 8088.618\n-----------------------------------------------------\nEpoch[72/100] Loss: 8054.846 BCE: 8054.758 KL: 0.087\nEpoch[72/100] Loss: 8067.386 BCE: 8067.298 KL: 0.088\n0.5 0.5\n0.5 0.5\n0.5 0.5\nSave samples finished...\nEpoch[72/100] Training Loss: 8069.265\nEpoch[72/100] Testing Loss: 8092.174\n-----------------------------------------------------\nEpoch[73/100] Loss: 8080.381 BCE: 8080.291 KL: 0.091\nEpoch[73/100] Loss: 8051.352 BCE: 8051.263 KL: 0.089\n0.5 0.5\n0.5 0.5\n0.5 0.5\nSave samples finished...\nEpoch[73/100] Training Loss: 8069.120\nEpoch[73/100] Testing Loss: 8091.098\n-----------------------------------------------------\nEpoch[74/100] Loss: 8063.672 BCE: 8063.585 KL: 0.087\nEpoch[74/100] Loss: 8070.878 BCE: 8070.790 KL: 0.089\n0.5 0.5\n0.5 0.5\n0.5 0.5\nSave samples finished...\nEpoch[74/100] Training Loss: 8068.876\nEpoch[74/100] Testing Loss: 8089.398\n-----------------------------------------------------\nEpoch[75/100] Loss: 8072.867 BCE: 8072.779 KL: 0.088\nEpoch[75/100] Loss: 8058.639 BCE: 8058.549 KL: 0.090\n0.5 0.5\n0.5 0.5\n0.5 0.5\nSave samples finished...\nEpoch[75/100] Training Loss: 8068.402\nEpoch[75/100] Testing Loss: 8089.575\n-----------------------------------------------------\nEpoch[76/100] Loss: 8076.236 BCE: 8076.148 KL: 0.088\nEpoch[76/100] Loss: 8049.753 BCE: 8049.666 KL: 0.088\n0.5 0.5\n0.5 0.5\n0.5 0.5\nSave samples finished...\nEpoch[76/100] Training Loss: 8068.663\nEpoch[76/100] Testing Loss: 8088.764\n-----------------------------------------------------\nEpoch[77/100] Loss: 8062.713 BCE: 8062.625 KL: 0.088\nEpoch[77/100] Loss: 8071.189 BCE: 8071.103 KL: 0.086\n0.5 0.5\n0.5 0.5\n0.5 0.5\nSave samples finished...\nEpoch[77/100] Training Loss: 8068.211\nEpoch[77/100] Testing Loss: 8088.921\n-----------------------------------------------------\nEpoch[78/100] Loss: 8092.584 BCE: 8092.494 KL: 0.090\nEpoch[78/100] Loss: 8050.071 BCE: 8049.983 KL: 0.088\n0.5 0.5\n0.5 0.5\n0.5 0.5\nSave samples finished...\nEpoch[78/100] Training Loss: 8068.438\nEpoch[78/100] Testing Loss: 8090.653\n-----------------------------------------------------\nEpoch[79/100] Loss: 8074.665 BCE: 8074.575 KL: 0.089\nEpoch[79/100] Loss: 8086.733 BCE: 8086.646 KL: 0.087\n0.5 0.5\n0.5 0.5\n0.5 0.5\nSave samples finished...\nEpoch[79/100] Training Loss: 8068.406\nEpoch[79/100] Testing Loss: 8088.329\n-----------------------------------------------------\nEpoch[80/100] Loss: 8059.155 BCE: 8059.069 KL: 0.086\nEpoch[80/100] Loss: 8095.986 BCE: 8095.896 KL: 0.090\n0.5 0.5\n0.5 0.5\n0.5 0.5\nSave samples finished...\nEpoch[80/100] Training Loss: 8068.226\nEpoch[80/100] Testing Loss: 8088.272\n-----------------------------------------------------\nEpoch[81/100] Loss: 8060.495 BCE: 8060.407 KL: 0.088\nEpoch[81/100] Loss: 8058.300 BCE: 8058.213 KL: 0.087\n0.5 0.5\n0.5 0.5\n0.5 0.5\nSave samples finished...\nEpoch[81/100] Training Loss: 8067.802\nEpoch[81/100] Testing Loss: 8089.007\n-----------------------------------------------------\nEpoch[82/100] Loss: 8067.010 BCE: 8066.922 KL: 0.088\nEpoch[82/100] Loss: 8059.705 BCE: 8059.616 KL: 0.088\n0.5 0.5\n0.5 0.5\n0.5 0.5\nSave samples finished...\nEpoch[82/100] Training Loss: 8068.170\nEpoch[82/100] Testing Loss: 8089.829\n-----------------------------------------------------\nEpoch[83/100] Loss: 8058.832 BCE: 8058.746 KL: 0.086\nEpoch[83/100] Loss: 8059.685 BCE: 8059.597 KL: 0.088\n0.5 0.5\n0.5 0.5\n0.5 0.5\nSave samples finished...\nEpoch[83/100] Training Loss: 8067.819\nEpoch[83/100] Testing Loss: 8092.042\n-----------------------------------------------------\nEpoch[84/100] Loss: 8062.629 BCE: 8062.541 KL: 0.089\nEpoch[84/100] Loss: 8091.881 BCE: 8091.793 KL: 0.088\n0.5 0.5\n0.5 0.5\n0.5 0.5\nSave samples finished...\nEpoch[84/100] Training Loss: 8067.954\nEpoch[84/100] Testing Loss: 8088.350\n-----------------------------------------------------\nEpoch[85/100] Loss: 8058.196 BCE: 8058.109 KL: 0.087\nEpoch[85/100] Loss: 8096.062 BCE: 8095.974 KL: 0.089\n0.5 0.5\n0.5 0.5\n0.5 0.5\nSave samples finished...\nEpoch[85/100] Training Loss: 8067.817\nEpoch[85/100] Testing Loss: 8089.035\n-----------------------------------------------------\nEpoch[86/100] Loss: 8041.117 BCE: 8041.029 KL: 0.088\nEpoch[86/100] Loss: 8079.544 BCE: 8079.456 KL: 0.088\n0.5 0.5\n0.5 0.5\n0.5 0.5\nSave samples finished...\nEpoch[86/100] Training Loss: 8067.677\nEpoch[86/100] Testing Loss: 8088.154\n-----------------------------------------------------\nEpoch[87/100] Loss: 8081.789 BCE: 8081.702 KL: 0.087\nEpoch[87/100] Loss: 8061.716 BCE: 8061.628 KL: 0.088\n0.5 0.5\n0.5 0.5\n0.5 0.5\nSave samples finished...\nEpoch[87/100] Training Loss: 8067.614\nEpoch[87/100] Testing Loss: 8088.468\n-----------------------------------------------------\nEpoch[88/100] Loss: 8075.957 BCE: 8075.869 KL: 0.088\nEpoch[88/100] Loss: 8073.928 BCE: 8073.841 KL: 0.087\n0.5 0.5\n0.5 0.5\n0.5 0.5\nSave samples finished...\nEpoch[88/100] Training Loss: 8067.547\nEpoch[88/100] Testing Loss: 8091.329\n-----------------------------------------------------\nEpoch[89/100] Loss: 8066.630 BCE: 8066.543 KL: 0.086\nEpoch[89/100] Loss: 8070.528 BCE: 8070.440 KL: 0.088\n0.5 0.5\n0.5 0.5\n0.5 0.5\nSave samples finished...\nEpoch[89/100] Training Loss: 8067.662\nEpoch[89/100] Testing Loss: 8088.451\n-----------------------------------------------------\nEpoch[90/100] Loss: 8065.992 BCE: 8065.905 KL: 0.087\nEpoch[90/100] Loss: 8086.324 BCE: 8086.233 KL: 0.090\n0.5 0.5\n0.5 0.5\n0.5 0.5\nSave samples finished...\nEpoch[90/100] Training Loss: 8067.371\nEpoch[90/100] Testing Loss: 8088.969\n-----------------------------------------------------\nEpoch[91/100] Loss: 8054.639 BCE: 8054.552 KL: 0.087\nEpoch[91/100] Loss: 8108.012 BCE: 8107.921 KL: 0.091\n0.5 0.5\n0.5 0.5\n0.5 0.5\nSave samples finished...\nEpoch[91/100] Training Loss: 8067.102\nEpoch[91/100] Testing Loss: 8088.594\n-----------------------------------------------------\nEpoch[92/100] Loss: 8071.809 BCE: 8071.721 KL: 0.088\nEpoch[92/100] Loss: 8051.269 BCE: 8051.181 KL: 0.088\n0.5 0.5\n0.5 0.5\n0.5 0.5\nSave samples finished...\nEpoch[92/100] Training Loss: 8067.228\nEpoch[92/100] Testing Loss: 8088.946\n-----------------------------------------------------\nEpoch[93/100] Loss: 8057.986 BCE: 8057.898 KL: 0.088\nEpoch[93/100] Loss: 8074.147 BCE: 8074.060 KL: 0.087\n0.5 0.5\n0.5 0.5\n0.5 0.5\nSave samples finished...\nEpoch[93/100] Training Loss: 8067.198\nEpoch[93/100] Testing Loss: 8089.432\n-----------------------------------------------------\nEpoch[94/100] Loss: 8038.417 BCE: 8038.330 KL: 0.087\nEpoch[94/100] Loss: 8072.872 BCE: 8072.785 KL: 0.087\n0.5 0.5\n0.5 0.5\n0.5 0.5\nSave samples finished...\nEpoch[94/100] Training Loss: 8067.046\nEpoch[94/100] Testing Loss: 8091.839\n-----------------------------------------------------\nEpoch[95/100] Loss: 8071.289 BCE: 8071.201 KL: 0.088\nEpoch[95/100] Loss: 8079.332 BCE: 8079.245 KL: 0.087\n0.5 0.5\n0.5 0.5\n0.5 0.5\nSave samples finished...\nEpoch[95/100] Training Loss: 8066.757\nEpoch[95/100] Testing Loss: 8088.923\n-----------------------------------------------------\nEpoch[96/100] Loss: 8074.532 BCE: 8074.444 KL: 0.088\nEpoch[96/100] Loss: 8097.610 BCE: 8097.520 KL: 0.090\n0.5 0.5\n0.5 0.5\n0.5 0.5\nSave samples finished...\nEpoch[96/100] Training Loss: 8067.304\nEpoch[96/100] Testing Loss: 8090.051\n-----------------------------------------------------\nEpoch[97/100] Loss: 8066.550 BCE: 8066.463 KL: 0.087\nEpoch[97/100] Loss: 8039.820 BCE: 8039.737 KL: 0.083\n0.5 0.5\n0.5 0.5\n0.5 0.5\nSave samples finished...\nEpoch[97/100] Training Loss: 8066.990\nEpoch[97/100] Testing Loss: 8092.182\n-----------------------------------------------------\nEpoch[98/100] Loss: 8059.920 BCE: 8059.836 KL: 0.085\nEpoch[98/100] Loss: 8066.864 BCE: 8066.775 KL: 0.089\n0.5 0.5\n0.5 0.5\n0.5 0.5\nSave samples finished...\nEpoch[98/100] Training Loss: 8066.757\nEpoch[98/100] Testing Loss: 8091.635\n-----------------------------------------------------\nEpoch[99/100] Loss: 8087.557 BCE: 8087.468 KL: 0.088\nEpoch[99/100] Loss: 8055.248 BCE: 8055.160 KL: 0.087\n0.5 0.5\n0.5 0.5\n0.5 0.5\nSave samples finished...\nEpoch[99/100] Training Loss: 8066.468\nEpoch[99/100] Testing Loss: 8088.549\n-----------------------------------------------------\nEpoch[100/100] Loss: 8056.681 BCE: 8056.593 KL: 0.088\nEpoch[100/100] Loss: 8082.764 BCE: 8082.676 KL: 0.088\n0.5 0.5\n0.5 0.5\n0.5 0.5\nSave samples finished...\nEpoch[100/100] Training Loss: 8066.820\nEpoch[100/100] Testing Loss: 8089.116\n-----------------------------------------------------\n"
    }
   ],
   "source": [
    "vae = VAE()\n",
    "optimizer = torch.optim.Adam(vae.parameters(), lr=1e-3)\n",
    "\n",
    "epochs = 100\n",
    "save_interval = 200\n",
    "loss_record = []\n",
    "\n",
    "# sample\n",
    "sample = Variable(torch.randn(batch_size, 32))\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    train_loss = 0\n",
    "    test_loss = 0\n",
    "    # num = 0\n",
    "\n",
    "    # for training...\n",
    "    for idx, (images, _) in enumerate(trainLoader):\n",
    "        # num += 1\n",
    "        # images = images/255. # normalize\n",
    "        recon_images, mu, logvar = vae(images)\n",
    "        loss, bce, kld = loss_fn(recon_images, images, mu, logvar)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item()\n",
    "\n",
    "        if idx % save_interval == 0:\n",
    "            to_print = \"Epoch[{}/{}] Loss: {:.3f} BCE: {:.3f} KL: {:.3f}\".format(epoch+1, epochs, loss.item()/batch_size, bce.item()/batch_size, kld.item()/batch_size)\n",
    "            print(to_print)\n",
    "\n",
    "            \n",
    "    # print(vae.fc3(sample).shape)\n",
    "    sample_recon = vae.decoder(vae.fc3(sample).view(batch_size, 1024, 1, 1))\n",
    "    save_image(sample_recon.data.view(batch_size, 3, 64, 64), './result/kl100/un_epoch_' +str(epoch) + '.png')\n",
    "    # save_image(UnNormalization(sample_recon.data.view(batch_size, 3, 64, 64)), './result/un_epoch_' +str(epoch) + '.png') # 拿掉unnirmalize\n",
    "    print(\"Save samples finished...\")\n",
    "    \n",
    "    # save record\n",
    "    loss_record.append(train_loss/len(trainSet))\n",
    "    \n",
    "    to_print = \"Epoch[{}/{}] Training Loss: {:.3f}\".format(epoch+1,epochs, train_loss/len(trainSet))\n",
    "    print(to_print)\n",
    "    \n",
    "    # for testing... \n",
    "    for idx, (images, _) in enumerate(testLoader):\n",
    "        # images = images/255. # normalize\n",
    "        recon_images, mu, logvar = vae(images)\n",
    "        loss, _, _ = loss_fn(recon_images, images, mu, logvar)\n",
    "        test_loss += loss\n",
    "\n",
    "        # sample = Variable(torch.randn(64, 20))\n",
    "    \n",
    "    to_print = \"Epoch[{}/{}] Testing Loss: {:.3f}\".format(epoch+1,epochs, test_loss/len(testSet))\n",
    "    print(to_print)\n",
    "    \n",
    "    # when epoch finishing...\n",
    "    img = testSet[randint(1, 100)][0].unsqueeze(0)\n",
    "    compare_img = compare(img)#*255\n",
    "    save_image(compare_img.data, 'sample_image.png')\n",
    "    # display(Image('sample_image.png',width=700, unconfined=True))    \n",
    "    print('-----------------------------------------------------')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "[tensor(1.5889e+08, grad_fn=<AddBackward0>)]"
     },
     "metadata": {},
     "execution_count": 70
    }
   ],
   "source": [
    "loss_record"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "fc version\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "----------------------------------------------------------------\n        Layer (type)               Output Shape         Param #\n================================================================\n            Linear-1                 [-1, 1000]      12,289,000\n            Linear-2                   [-1, 50]          50,050\n            Linear-3                   [-1, 50]          50,050\n            Linear-4                 [-1, 1000]          51,000\n            Linear-5                [-1, 12288]      12,300,288\n================================================================\nTotal params: 24,740,388\nTrainable params: 24,740,388\nNon-trainable params: 0\n----------------------------------------------------------------\nInput size (MB): 0.05\nForward/backward pass size (MB): 0.11\nParams size (MB): 94.38\nEstimated Total Size (MB): 94.53\n----------------------------------------------------------------\n"
    }
   ],
   "source": [
    "# fc VAE\n",
    "class VAE(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(VAE, self).__init__()\n",
    "        \n",
    "        # self.fc1 = nn.Linear(64*64*3, 400)\n",
    "        # self.fc2_1 = nn.Linear(400,20)\n",
    "        # self.fc2_2 = nn.Linear(400,20)\n",
    "        # self.fc3 = nn.Linear(20,400)\n",
    "        # self.fc4 = nn.Linear(400,64*64*3)\n",
    "        self.fc1 = nn.Linear(64*64*3, 1000)\n",
    "        self.fc2_1 = nn.Linear(1000,50)\n",
    "        self.fc2_2 = nn.Linear(1000,50)\n",
    "        self.fc3 = nn.Linear(50,1000)\n",
    "        self.fc4 = nn.Linear(1000,64*64*3)\n",
    "\n",
    "    def encode(self, x):\n",
    "        h1 = F.relu(self.fc1(x))\n",
    "        return self.fc2_1(h1), self.fc2_2(h1) # mu and var\n",
    "    \n",
    "    def reparameterize(self, mu, logvar):\n",
    "        std = torch.exp(.5*logvar)\n",
    "        eps = torch.randn_like(std)\n",
    "        return mu + eps*std\n",
    "    \n",
    "    def decode(self, z):\n",
    "        h3 = F.relu(self.fc3(z))\n",
    "        return torch.sigmoid(self.fc4(h3))\n",
    "\n",
    "    def forward(self, x):\n",
    "        mu, logvar = self.encode(x.view(-1, 64*64*3))\n",
    "        z = self.reparameterize(mu, logvar)\n",
    "        return self.decode(z), mu, logvar\n",
    "    # Reconstruction + KL divergence losses summed over all elements and batch\n",
    "def loss_func(recon_x, x, mu, logvar):\n",
    "    bce_loss = F.binary_cross_entropy(recon_x, x.view(-1, 64*64*3), reduction='sum')\n",
    "    kl_divergence = -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp())\n",
    "    return bce_loss+kl_divergence\n",
    "vae = VAE()\n",
    "optimizer = optim.Adam(vae.parameters(), lr=1e-3)\n",
    "\n",
    "from torchvision import models\n",
    "from torchsummary import summary\n",
    "\n",
    "summary(vae, (3, 64, 64))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2 fc\n",
    "def train(epoch):\n",
    "    train_loss = 0\n",
    "    for batch_idx, (data, _) in enumerate(train_loader):\n",
    "        optimizer.zero_grad()\n",
    "        recon_batch, mu, logvar = vae(data)\n",
    "        loss = loss_func(recon_batch, data, mu, logvar)\n",
    "        loss.backward()\n",
    "        train_loss += loss.item()\n",
    "        optimizer.step()\n",
    "        # if batch_idx % save_interval == 0:\n",
    "        #      print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "        #         epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "        #         100. * batch_idx / len(train_loader),\n",
    "        #         loss.item() / len(data)))\n",
    "    print('====> Epoch: {} Average loss: {:.4f}'.format(\n",
    "          epoch, train_loss / len(train_loader.dataset)))\n",
    "def test(epoch):\n",
    "    vae.eval()\n",
    "    test_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for i, (data, _) in enumerate(test_loader):\n",
    "            recon_batch, mu, logvar = model(data)\n",
    "            test_loss += loss_function(recon_batch, data, mu, logvar).item()\n",
    "            if i == 0:\n",
    "                n = min(data.size(0), 8)\n",
    "                comparison = torch.cat([data[:n],\n",
    "                                      recon_batch.view(batch_size, 1, 28, 28)[:n]])\n",
    "                save_image(comparison.cpu(),\n",
    "                         'results/reconstruction_' + str(epoch) + '.png', nrow=n)\n",
    "\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "    print('====> Test set loss: {:.4f}'.format(test_loss))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from torchvision import models\n",
    "# from torchsummary import summary\n",
    "\n",
    "# # vgg = models.vgg16()\n",
    "# summary(vae, (3, 64, 64))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "tags": [
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend"
    ]
   },
   "outputs": [],
   "source": [
    "# for epoch in range(1, epochs + 1):\n",
    "#     train(epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 1 cnn\n",
    "# for epoch in range(epochs):\n",
    "#     # vae.train()\n",
    "#     epoch_loss = 0\n",
    "#     for batch_idx, (data, _) in enumerate(train_loader, 0):\n",
    "#         #train network\n",
    "#         data = Variable(data)\n",
    "#         print(data.shape)\n",
    "#         optimizer.zero_grad()\n",
    "#         recon_x, mu, logvar = vae.forward(data)\n",
    "#         loss = loss_func(recon_x, data, mu, logvar)\n",
    "#         loss.backward()\n",
    "#         total_loss += loss#.data[0]\n",
    "#         optimizer.step()\n",
    "\n",
    "#         if batch_idx % log_interval == 0:\n",
    "#             sample = Variable(torch.randn(64, latent_code))\n",
    "#             sample = vae.decoder(vae.fc2(sample).view(64, 128, 7, 7))\n",
    "#             save_image(sample.data.view(64, 1, 28, 28),'./result/mysample_' + str(epoch) + '.png')\n",
    "#             print('Train Epoch:{} -- [{}/{} ({:.0f}%)] -- Loss:{:.6f}'.format(epoch, i*len(data), len(train_loader.dataset), 100.*i/len(train_loader), loss/len(data)))\n",
    "#             print('====> Epoch: {} Average loss: {:.4f}'.format(epoch, total_loss / len(train_loader.dataset)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "(64, 64)\n"
    }
   ],
   "source": [
    "# '''\n",
    "# 試著印出圖片\n",
    "# 並確認圖片大小\n",
    "# '''\n",
    "# from matplotlib.pyplot import imshow\n",
    "# import numpy as np\n",
    "# from PIL import Image\n",
    "# import glob\n",
    "\n",
    "# # %matplotlib inline\n",
    "\n",
    "# image_list = []\n",
    "# image_size = []\n",
    "# for filename in glob.glob('../anime-faces/data/*.png'):\n",
    "#     img = Image.open(filename)\n",
    "#     image_list.append(img)\n",
    "#     image_size.append(img.size)\n",
    "#     img.load()\n",
    "# # img = Image.open('../anime-faces/data/1.png', 'r')\n",
    "# # imshow(np.asarray(img))\n",
    "# # print(img.size)\n",
    "# def unique(list1):\n",
    "#     unique_list = []\n",
    "#     for x in list1:\n",
    "#         if x not in unique_list: \n",
    "#             unique_list.append(x)\n",
    "#     for x in unique_list: \n",
    "#         print(x)\n",
    "# unique(image_size) # size 皆是 64*64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python38264bit80e5783b53564d659ac8b5891bf20cfd",
   "display_name": "Python 3.8.2 64-bit"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}